{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"mgmvS9mb0r1p"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 1s 0us/step\n","Epoch 1/10\n","782/782 [==============================] - 107s 135ms/step - loss: 0.3974 - accuracy: 0.8068 - val_loss: 0.2752 - val_accuracy: 0.8846\n","Epoch 2/10\n","782/782 [==============================] - 105s 134ms/step - loss: 0.2136 - accuracy: 0.9166 - val_loss: 0.2596 - val_accuracy: 0.8940\n","Epoch 3/10\n","782/782 [==============================] - 103s 132ms/step - loss: 0.1295 - accuracy: 0.9530 - val_loss: 0.2897 - val_accuracy: 0.8890\n","Epoch 4/10\n","782/782 [==============================] - 107s 137ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.3936 - val_accuracy: 0.8744\n","Epoch 5/10\n","782/782 [==============================] - 105s 134ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.4608 - val_accuracy: 0.8812\n","Epoch 6/10\n","782/782 [==============================] - 126s 162ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.5287 - val_accuracy: 0.8790\n","Epoch 7/10\n","782/782 [==============================] - 106s 135ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.5428 - val_accuracy: 0.8798\n","Epoch 8/10\n","782/782 [==============================] - 105s 134ms/step - loss: 0.0191 - accuracy: 0.9930 - val_loss: 0.6006 - val_accuracy: 0.8699\n","Epoch 9/10\n","782/782 [==============================] - 104s 133ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.6230 - val_accuracy: 0.8816\n","Epoch 10/10\n","782/782 [==============================] - 100s 128ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.6290 - val_accuracy: 0.8801\n","782/782 [==============================] - 20s 26ms/step - loss: 0.6290 - accuracy: 0.8801\n","Test score: 0.6290449500083923\n","Test accuracy: 0.8801199793815613\n"]}],"source":["import numpy as np\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n","\n","# Set hyperparameters\n","max_features = 5000\n","max_len = 400\n","embedding_dim = 50\n","filters = 250\n","kernel_size = 3\n","hidden_dims = 250\n","dropout_prob = 0.5\n","batch_size = 32\n","epochs = 10\n","\n","# Load dataset\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","# Pad sequences\n","X_train = pad_sequences(X_train, maxlen=max_len)\n","X_test = pad_sequences(X_test, maxlen=max_len)\n","\n","# Build model\n","model = Sequential()\n","model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n","model.add(Conv1D(filters, kernel_size, activation='relu'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dense(hidden_dims, activation='relu'))\n","model.add(Dropout(dropout_prob))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n","\n","# Evaluate model\n","score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":713,"status":"ok","timestamp":1681713530488,"user":{"displayName":"gorle kavyanjali","userId":"02988688625106284954"},"user_tz":-330},"id":"zVgEzGyr5E-D","outputId":"e7be8c23-04fa-40e7-cd13-cf753cd73083"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 23ms/step\n","Predicted label: positive, Predicted probability: [0.9764813]\n"]}],"source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Define function to preprocess input text\n","def preprocess_text(text):\n","    # Tokenize text\n","    tokenizer = Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(text)\n","    seq = tokenizer.texts_to_sequences(text)\n","    # Pad sequences\n","    padded = pad_sequences(seq, maxlen=max_len)\n","    return padded\n","\n","# Define function to predict sentiment\n","def predict_sentiment(model, text):\n","    # Preprocess input text\n","    padded_text = preprocess_text([text])\n","    # Make prediction\n","    pred = model.predict(padded_text)[0]\n","    # Convert prediction to label\n","    label = \"positive\" if pred \u003e= 0.5 else \"negative\"\n","    return label, pred\n","\n","# Example usage\n","new_review = \"The movie was so good\"\n","label, pred = predict_sentiment(model, new_review)\n","print(\"Predicted label: {}, Predicted probability: {}\".format(label, pred))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOj/23yQPg0lZJBB8whTV53","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}